<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-eval/blaser">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">BLASER: an evaluation metric of translation accuracy for speech and text | stopes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://facebookresearch.github.io/stopes/docs/eval/blaser"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="BLASER: an evaluation metric of translation accuracy for speech and text | stopes"><meta data-rh="true" name="description" content="BLASER leverages a multilingual multimodal encoder to directly encode the speech segments for source input, translation output and (optionally) reference into a shared embedding space and computes a score of the translation quality that can be used as a proxy to human evaluation."><meta data-rh="true" property="og:description" content="BLASER leverages a multilingual multimodal encoder to directly encode the speech segments for source input, translation output and (optionally) reference into a shared embedding space and computes a score of the translation quality that can be used as a proxy to human evaluation."><link data-rh="true" rel="icon" href="/stopes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://facebookresearch.github.io/stopes/docs/eval/blaser"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/eval/blaser" hreflang="en"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/eval/blaser" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZRD7WBVGH"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-9ZRD7WBVGH",{anonymize_ip:!0})</script><link rel="stylesheet" href="/stopes/assets/css/styles.4435c2e4.css">
<link rel="preload" href="/stopes/assets/js/runtime~main.6bbf2219.js" as="script">
<link rel="preload" href="/stopes/assets/js/main.cb8faedb.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/stopes/"><div class="navbar__logo"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">stopes</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/quickstart">Quickstart</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/stopes">Framework</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/pipelines/global_mining">State-of-the-art Pipelines</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><a href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">NLLB<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/stopes/docs/quickstart">Getting started with mining</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/stopes-modules">stopes Modules</a><button aria-label="Toggle the collapsible sidebar category &#x27;stopes Modules&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/prebuilt-pipelines">Prebuilt Pipelines</a><button aria-label="Toggle the collapsible sidebar category &#x27;Prebuilt Pipelines&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Evaluation Toolkit&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/eval/alti">ALTI+</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/stopes/docs/eval/blaser">BLASER: an evaluation metric of translation accuracy for speech and text</a></li></ul></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/stopes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/stopes/docs/category/evaluation-toolkit"><span itemprop="name">Evaluation Toolkit</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">BLASER: an evaluation metric of translation accuracy for speech and text</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>BLASER: an evaluation metric of translation accuracy for speech and text</h1><p>BLASER leverages a multilingual multimodal encoder to directly encode the speech segments for source input, translation output and (optionally) reference into a shared embedding space and computes a score of the translation quality that can be used as a proxy to human evaluation.</p><p>There are two generations of BLASER models:</p><ol><li>BLASER is based on <a href="https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_matrix/speech_laser_encoders.md" target="_blank" rel="noopener noreferrer">SpeechLASER embeddings</a>, is intended to use with speech only, and always requires a reference translation.</li><li>BLASER-2.0 is based on <a href="https://github.com/facebookresearch/SONAR" target="_blank" rel="noopener noreferrer">SONAR embeddings</a>, supports speech and texts interchangeably, and has a reference-free version (BLASER-2.0 QE).</li></ol><p>Below, both these model generations are presented.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="blaser-20">BLASER 2.0<a class="hash-link" href="#blaser-20" title="Direct link to heading">​</a></h2><p>BLASER 2.0 is a family of models for automatic evaluation of machine translation quality based on SONAR embeddings, presented in the <a href="https://arxiv.org/abs/2308.11596" target="_blank" rel="noopener noreferrer">SeamlessM4T</a> paper. They predict <a href="https://github.com/facebookresearch/fairseq/tree/nllb/examples/nllb/human_XSTS_eval" target="_blank" rel="noopener noreferrer">cross-lingual semantic similarity</a> between the translation and the source (optionally, also using a reference translation).</p><p>There are two BLASER 2.0 supervised models: <a href="https://huggingface.co/facebook/blaser-2.0-ref" target="_blank" rel="noopener noreferrer">facebook/blaser-2.0-ref</a> that requires a reference translation, and <a href="https://huggingface.co/facebook/blaser-2.0-qe" target="_blank" rel="noopener noreferrer">facebook/blaser-2.0-qe</a> that uses only source and machine translation as inputs. Both can work with text or speech interchangeably. Additionally, we compute unsupervised scores as cosine similarity between the embeddings.</p><p>The code for BLASER 2.0, as well as for the underlying SONAR text and speech encoders, is published in the <a href="https://github.com/facebookresearch/SONAR" target="_blank" rel="noopener noreferrer">SONAR</a> repository.</p><p>Here, we present a script <code>stopes/eval/blaser/blaser2.py</code>, just to illustrate a possible usage of BLASER 2.0. If you have a <code>.tsv</code> file with the columns <code>src_audio</code>, <code>ref_audio</code>, and <code>tgt_audio</code>, with the paths to <code>.wav</code> files of English source, reference translation into French, and system translation, you can compute BLASER scores for them with the following code:</p><div class="language-Python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from stopes.eval.blaser.blaser2 import compute_blaser2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">(src_embs, ref_embs, tgt_embs), df_with_scores = compute_blaser2(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    data_path=PATH_TO_THE_FILE,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    src_column=&quot;src_audio&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    ref_column=&quot;ref_audio&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tgt_column=&quot;tgt_audio&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    blaser_path=&quot;blaser_2_0_ref&quot;,  # or blaser_2_0_qe, if you don&#x27;t use references</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    src_lang=&quot;eng&quot;,  # lookup language codes on SONAR model cards</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tgt_lang=&quot;fra&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    src_is_speech=True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tgt_is_speech=True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">mean_score = df_with_scores.mean(numeric_only=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(mean_score.unsupervised_scores)  # a number usually between 0 and 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(mean_score.supervised_scores)    # a number usually between 1 and 5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>To run this script, you will need to install <a href="https://github.com/facebookresearch/fairseq2" target="_blank" rel="noopener noreferrer">fairseq2</a> and <a href="https://github.com/facebookresearch/SONAR" target="_blank" rel="noopener noreferrer">SONAR</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="blaser-a-text-free-speech-to-speech-translation-evaluation-metric">BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric<a class="hash-link" href="#blaser-a-text-free-speech-to-speech-translation-evaluation-metric" title="Direct link to heading">​</a></h2><p>BLASER leverages a multilingual multimodal encoder to directly encode the speech segments for source input, translation output and reference into a shared embedding space and computes a score of the translation quality that can be used as a proxy to human evaluation.</p><p>In this folder you can find tools to use BLASER to score speech translation and to train the BLASER supervised model. You can also download a <a href="http://dl.fbaipublicfiles.com/blaser/blaser.tar.gz" target="_blank" rel="noopener noreferrer">pre-trained model</a>.</p><p>BLASER relies on <a href="https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_matrix/speech_laser_encoders.md" target="_blank" rel="noopener noreferrer">SpeechLASER embeddings</a>, follow the instructions there to download the embeddings and embed your speech segments.</p><blockquote><p>[!NOTE]<!-- --> BlaserV2.0 has now been released and lives in the <a href="https://github.com/facebookresearch/SONAR#predicting-sentence-similarity-with-blaser-20-models" target="_blank" rel="noopener noreferrer">SONAR repository</a>. We recommend using this new model and embedding space for your future uses of BLASER evalution</p></blockquote><h3 class="anchor anchorWithStickyNavbar_LWe7" id="files">Files<a class="hash-link" href="#files" title="Direct link to heading">​</a></h3><ul><li><code>model.py</code> contains the BLASER supervised model definition.</li><li><code>train.py</code> contains a script that you can use to train the BLASER model.</li><li><code>score.py</code> contains a script that you can use to score speech segments translations.</li></ul><p>The train and score scripts are configured using <a href="https://hydra.cc/" target="_blank" rel="noopener noreferrer">hydra</a>, you can look at the base configurations in <code>blaser/conf/score.yaml</code> and <code>blaser/conf/train.yaml</code>, you will have to specify the <code>???</code> fields, either in your own configs, or over the CLI. Both scripts take pre-embedded files.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="install">Install<a class="hash-link" href="#install" title="Direct link to heading">​</a></h3><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">git clone https://github.com/facebookresearch/stopes.git</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd stopes</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install -e &#x27;.[blaser]&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-the-pipeline">Using the pipeline<a class="hash-link" href="#using-the-pipeline" title="Direct link to heading">​</a></h3><p>Blaser requires embedded speech segments to compute the evaluation metric. A good way to get these embeddings is to use <a href="https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_matrix/speech_laser_encoders.md" target="_blank" rel="noopener noreferrer">SpeechLASER embeddings</a>.</p><p>We provide a pipeline that will compute the embeddings and feed them to the blaser model for you.</p><p><strong> Model </strong></p><p>You can download the model from <a href="https://dl.fbaipublicfiles.com/blaser/blaser.tar.gz" target="_blank" rel="noopener noreferrer">here</a>.</p><p><strong> Requirements </strong></p><p>To be able to use this pipeline, you will need the version of fairseq that has the Wav2VevLaser model implementation, this is currently in the <code>ust</code> branch of fairseq. Make sure to clone the repository, switch to that branch and install fairseq in your environment with: <code>pip install -e .</code>. It is recommended to do this before install stopes as per above.</p><p><strong> Run the pipeline </strong></p><p>You will need to pass three sets of speech segments to get a blaser score:</p><ul><li>the source audio (<code>src</code>)</li><li>the translated audio (<code>target</code>)</li><li>the reference audio (<code>ref</code>)</li></ul><p>The set of speech segments have to be organised in a tsv manifest pointing to the audio files. The format for each input audio data tsv file is:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;root_dir&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;audio_path&gt;\t&lt;num_frames&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;audio_path&gt;\t&lt;num_frames&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Rows in each manifest TSV files should align (line 1 of the src manifest should be translated on line 1 of the tgt manifest).</p><ul><li><code>root_dir</code> is on the first line of the TSV, it&#x27;s a path to where all the following files can be found</li><li><code>audio_path</code> can be either:<ul><li>a filename in <code>root_dir</code> for a .npy/.wav/.flac/.ogg file</li><li>a filename of stored ZIP file, in <code>root_dir</code>, with slicing info: &quot;<!-- -->[zip_path]<!-- -->:<!-- -->[offset]<!-- -->:<!-- -->[length]<!-- -->&quot; to find the bytes in the uncompressed zip archive containing that particular file</li></ul></li></ul><p>Check out the <code>demo/iwslt_blaser_eval/mk_manifest.py</code> script to see how to generate such a manifest file.</p><p>You can then run the pipeline with:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m stopes.pipelines.eval.eval_blaser output_dir=YOUROUTPUTDIRECTORY src_manifest=PATHTOSOURCEMANIFEST.tsv tgt_manifest=PATHTOTARGETMANIFEST.tsv ref_manifest=PATHTOREFERENCEMANIFEST.tsv src_lang=en tgt_lang=de</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>where <code>src_lang</code> is the language of your source audio and tgt_lang is the target language. This is used to lookup the correct encoder model as specified by <code>stopes/pipelines/eval/conf/eval_blaser.yaml</code>. You can download pre-trained encoders from the <a href="https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_matrix/speech_laser_encoders.md" target="_blank" rel="noopener noreferrer">SpeechMatrix project</a>. By default, the encoder used for the reference is the same as the target one, you can override this with <code>ref_lang=..</code> in the command arguments.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="citation">Citation<a class="hash-link" href="#citation" title="Direct link to heading">​</a></h2><p>If you use <code>blaser</code> in your work or any of its models, please cite:</p><div class="language-bibtex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bibtex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@misc{blaser2022,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title={BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author={Mingda Chen and Paul-Ambroise Duquenne and Pierre Andrews and Justine Kao and Alexandre Mourachko and Holger Schwenk and Marta R. Costa-jussà},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year={2022}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  doi = {10.48550/ARXIV.2212.08486},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  url = {https://arxiv.org/abs/2212.08486},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  publisher = {arXiv},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If you use <code>blaser-2.0</code>, please cite:</p><div class="language-bibtex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bibtex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@article{seamlessm4t2023,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title={SeamlessM4T—Massively Multilingual \&amp; Multimodal Machine Translation},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author={{Seamless Communication}, Lo\&quot;{i}c Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-Ambroise Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman, Christopher Klaiber, Pengwei Li, Daniel Licht, Jean Maillard, Alice Rakotoarison, Kaushik Ram Sadagopan, Guillaume Wenzek, Ethan Ye,  Bapi Akula, Peng-Jen Chen, Naji El Hachem, Brian Ellis, Gabriel Mejia Gonzalez, Justin Haaheim, Prangthip Hansanti, Russ Howes, Bernie Huang, Min-Jae Hwang, Hirofumi Inaguma, Somya Jain, Elahe Kalbassi, Amanda Kallet, Ilia Kulikov, Janice Lam, Daniel Li, Xutai Ma, Ruslan Mavlyutov, Benjamin Peloquin, Mohamed Ramadan, Abinesh Ramakrishnan, Anna Sun, Kevin Tran, Tuan Tran, Igor Tufanov, Vish Vogeti, Carleigh Wood, Yilin Yang, Bokai Yu, Pierre Andrews, Can Balioglu, Marta R. Costa-juss\`{a}, Onur \,{C}elebi,Maha Elbayad,Cynthia Gao, Francisco Guzm\&#x27;an, Justine Kao, Ann Lee, Alexandre Mourachko, Juan Pino, Sravya Popuri, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Paden Tomasello, Changhan Wang, Jeff Wang, Skyler Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  journal={ArXiv},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year={2023}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="license">License<a class="hash-link" href="#license" title="Direct link to heading">​</a></h2><p><code>blaser</code> is MIT licensed, as found in the LICENSE file in the root directory.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/eval/blaser.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/stopes/docs/eval/alti"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">ALTI+</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#blaser-20" class="table-of-contents__link toc-highlight">BLASER 2.0</a></li><li><a href="#blaser-a-text-free-speech-to-speech-translation-evaluation-metric" class="table-of-contents__link toc-highlight">BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric</a><ul><li><a href="#files" class="table-of-contents__link toc-highlight">Files</a></li><li><a href="#install" class="table-of-contents__link toc-highlight">Install</a></li><li><a href="#using-the-pipeline" class="table-of-contents__link toc-highlight">Using the pipeline</a></li></ul></li><li><a href="#citation" class="table-of-contents__link toc-highlight">Citation</a></li><li><a href="#license" class="table-of-contents__link toc-highlight">License</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/pipelines/global_mining">Pipelines</a></li><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/stopes">stopes Modules</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/data-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Data Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/cookie-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Cookie Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.fb.com" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--light_HNdA footer__logo"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--dark_i4oU footer__logo"></a></div><div class="footer__copyright">Copyright © 2024 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/stopes/assets/js/runtime~main.6bbf2219.js"></script>
<script src="/stopes/assets/js/main.cb8faedb.js"></script>
</body>
</html>