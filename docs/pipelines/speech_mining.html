<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-pipelines/speech_mining">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Speech Mining Pipeline | stopes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://facebookresearch.github.io/stopes/docs/pipelines/speech_mining"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Speech Mining Pipeline | stopes"><meta data-rh="true" name="description" content="With the Seamless Communication project, FAIR has introduced a new mechanism for speech mining. In the stopesV1, you could mine large text datasets to create aligned text accross languages. This was useful to train machine translation algorithms. From stopesV2 onwards, we introduce a mechanism that lets you mine speech and text together accross languages to create aligned multimodal datasets for training and evaluating speech tasks. This mining is based on the SONAR multimodal/multilingual embedding space."><meta data-rh="true" property="og:description" content="With the Seamless Communication project, FAIR has introduced a new mechanism for speech mining. In the stopesV1, you could mine large text datasets to create aligned text accross languages. This was useful to train machine translation algorithms. From stopesV2 onwards, we introduce a mechanism that lets you mine speech and text together accross languages to create aligned multimodal datasets for training and evaluating speech tasks. This mining is based on the SONAR multimodal/multilingual embedding space."><link data-rh="true" rel="icon" href="/stopes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://facebookresearch.github.io/stopes/docs/pipelines/speech_mining"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/pipelines/speech_mining" hreflang="en"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/pipelines/speech_mining" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZRD7WBVGH"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-9ZRD7WBVGH",{anonymize_ip:!0})</script><link rel="stylesheet" href="/stopes/assets/css/styles.4435c2e4.css">
<link rel="preload" href="/stopes/assets/js/runtime~main.6bbf2219.js" as="script">
<link rel="preload" href="/stopes/assets/js/main.cb8faedb.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/stopes/"><div class="navbar__logo"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">stopes</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/quickstart">Quickstart</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/stopes">Framework</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/pipelines/global_mining">State-of-the-art Pipelines</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><a href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">NLLB<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/stopes/docs/quickstart">Getting started with mining</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/stopes-modules">stopes Modules</a><button aria-label="Toggle the collapsible sidebar category &#x27;stopes Modules&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/stopes/docs/category/prebuilt-pipelines">Prebuilt Pipelines</a><button aria-label="Toggle the collapsible sidebar category &#x27;Prebuilt Pipelines&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/expressive_alignments">Expressive parallel alignments</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/stopes/docs/pipelines/speech_mining">Speech Mining Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/global_mining">Global Mining Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/monolingual">NLLB Monolingual Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/distillation">NLLB Distillation Pipeline</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Evaluation Toolkit&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/stopes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/stopes/docs/category/prebuilt-pipelines"><span itemprop="name">Prebuilt Pipelines</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Speech Mining Pipeline</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Speech Mining Pipeline</h1><p>With the <a href="https://github.com/facebookresearch/seamless_communication" target="_blank" rel="noopener noreferrer">Seamless Communication project</a>, FAIR has introduced a new mechanism for speech mining. In the <code>stopesV1</code>, you could mine large text datasets to create aligned text accross languages. This was useful to train machine translation algorithms. From <code>stopesV2</code> onwards, we introduce a mechanism that lets you mine speech and text together accross languages to create aligned multimodal datasets for training and evaluating speech tasks. This mining is based on the <a href="https://github.com/facebookresearch/SONAR" target="_blank" rel="noopener noreferrer">SONAR multimodal/multilingual embedding space</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="installation">Installation<a class="hash-link" href="#installation" title="Direct link to heading">​</a></h2><p>Speech mining requires the installation of <a href="https://github.com/facebookresearch/fairseq2" target="_blank" rel="noopener noreferrer">fairseq2</a> and <a href="https://github.com/facebookresearch/SONAR" target="_blank" rel="noopener noreferrer">SONAR</a>. You can install these with:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install &#x27;stopes[speech,mining,sonar_mining]&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>or if you are installing a local checkout of this repository:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install &#x27;.[speech,mining,sonar_mining]&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The above message should install SONAR and fairseq2 with their default settings. If you want to install fairseq2 with custom support for your hardware (i.e. GPU suppport with different CUDA versions), see the installation instructions in the <a href="https://github.com/facebookresearch/fairseq2" target="_blank" rel="noopener noreferrer">fairseq2</a> documentation to build the package for your own machine.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="preset-configuration">Preset configuration<a class="hash-link" href="#preset-configuration" title="Direct link to heading">​</a></h2><p>The speech mining pipeline is an extension of the <a href="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining" target="_blank" rel="noopener noreferrer">global mining</a> pipeline. We recommend reading that page first to understand the base configuration for text to text mining.</p><p>While in the global mining, you run one encoder for all laguages, in speech mining, you can configure different encoders of different modalities (text or speech), depending on whether you want to mine text-text, speech-text, text-speech or speech-speech with the SONAR space encoders. You can do this within a language (e.g. to mine aligned text-speech in English), or accross languages (e.g. to mine aligned speech-speech between Catalan and Korean).</p><p>More specifically, in speech mining, we use a preset configuration to set up the embedding modules for each language under the <code>lang_configs</code>. Note that in your configuration, <code>lang_configs</code> might end up having multiple entries for the same language, but with different modalities.</p><p>Below is an example if you want to mine text-speech within French (i.e. aligning between French audios and text). You can just replace the <code>lang_configs</code> section in <code>stopes/pipelines/bitext/conf/preset/demo.yaml</code> with the following setting:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">lang_configs:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  frA:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    data:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_version: 23H1RCLSP</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      iteration: 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_shard_dir: /path/tothe/rawaudio/dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_type: speech</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      bname: speech</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_list: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_glob: ${.data_shard_dir}/speech/*.ogg</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      nl_file_template: &quot;{lang}.nl&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    embed_speech:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      preprocess: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      encoder:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _target_: stopes.modules.preprocess.mining_speech_encoder.Sonar2MiningSpeechEncoder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        encoder_model: NAME_OF_SONAR_ENCODER_MODEL</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _name: sonar2_speech_encoder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_model: null # unused</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_vocab: null # unused</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        mini_batch_size: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        fp16: true</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        gpu: true</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        num_processes: 4</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  fr:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    data:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_version: 23H1RCL</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      iteration: 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_shard_dir: /path/tothe/rawtext/dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_type: text</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      bname: text</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_list: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_glob: ${.data_shard_dir}/text/text.txt</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      meta_glob: ${.data_shard_dir}/text/meta.txt</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      nl_file_template: &quot;{lang}.nl&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    embed_text:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      encoder:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _target_: stopes.modules.preprocess.sonar_sentence_encoder.SonarTextEncoder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _name: NAME_OF_SONAR_ENCODER_MODEL</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_model: null # unused</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_vocab: null # unused</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In this sample config, we have set a text data source <code>fr</code> and an audio data source <code>frA</code>. The example assumes they are the same language, but they could be different languages, or they could both be audio or text. The audio data source uses a SONAR speech encoder while the text source uses the text encoder. Make sure to refer to the SONAR model cards to choose the appropriate encoder model to specify in each config entry. Replace &quot;NAME_OF_SONAR_ENCODER_MODEL&quot; in the config above with the name of the SONAR model card (You can find the list of available model card in the <a href="https://github.com/facebookresearch/SONAR/tree/main/sonar/cards" target="_blank" rel="noopener noreferrer">SONAR Github repository</a>).</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="run-the-mining-pipeline">Run the mining pipeline<a class="hash-link" href="#run-the-mining-pipeline" title="Direct link to heading">​</a></h2><p>The above setting is analog to the <code>embed_text</code> step in the <a href="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining" target="_blank" rel="noopener noreferrer">global mining</a>. The different here is that we can use either <code>embed_speech</code> or <code>embed_text</code> to encode the data of different modalities. The rest of the mining pipeline is similar to the one described on the global mining page.</p><p>We provide the example preset in <code>stopes/pipelines/bitext/conf/preset/demo_speechmine.yaml</code>, so you can simply run:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m stopes.pipelines.bitext.global_mining_pipeline </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">frA </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">fr </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">demo_text_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">..</span><span class="token plain">./stopes-repo/demo </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">demo_audio_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">YOUR AUDIO DIR</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token plain"> +preset</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">demo_speechmine </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">output_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="audio-data-format-and-segmentation">Audio data format and segmentation<a class="hash-link" href="#audio-data-format-and-segmentation" title="Direct link to heading">​</a></h2><p>In order to run the above example, you would need to provide your own audio data. Note that the audio dataset shards are text files containing segmentation information about your raw audio. This follows the format:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">audio_file_name start_timestamp end_timestamp batch_no</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>where <code>start/end</code> timestamps are timestamps of a speech segment within the audio file. <code>batch_no</code> is a batching number for this segment. You can use it to batch segments of similar length together for faster embedding, or just leave it set to 0.</p><p>This means that you need to run the speech segmentation separately. There are many ways to segment audio, one of them is to use our internal VADSegmentation, found in <code>stopes.modules.speech.vad_segment_audio.VADSegmentAudioModule</code>. Below is the example of the updated <code>lang_configs</code> for the audio data with segmentation option:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">lang_configs:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  frA:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    data:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_version: 23H1RCLSP</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      iteration: 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      data_shard_dir: /path/tothe/segmented_dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_type: speech</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      bname: speech</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_list: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shard_glob: ${.data_shard_dir}/speech/*.ogg</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      nl_file_template: &quot;{lang}.nl&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    segment_audio:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      _target_: stopes.modules.speech.vad_segment_audio.VADSegmentAudioModule</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      lang: fr</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      shards: /path/tothe/rawaudio/dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      max_duration_in_seconds: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      output_dir: /path/tothe/segmented_dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      model: [MODEL_TO_SILERO_VAD]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      hard_limit_min_length: 1.0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    embed_speech:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      preprocess: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      encoder:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _target_: stopes.modules.preprocess.mining_speech_encoder.Sonar2MiningSpeechEncoder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        encoder_model: NAME_OF_SONAR_ENCODER_MODEL</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _name: sonar2_speech_encoder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_model: null # unused</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        spm_vocab: null # unused</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        mini_batch_size: null</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        fp16: true</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        gpu: true</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        num_processes: 4</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Where the <code>MODEL_TO_SILERO_VAD</code> point to the silero VAD checkpoint found in e.g. <a href="https://github.com/snakers4/silero-models" target="_blank" rel="noopener noreferrer">Silero models hub</a>.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/pipelines/speech_mining.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/stopes/docs/pipelines/expressive_alignments"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Expressive parallel alignments</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/stopes/docs/pipelines/global_mining"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Global Mining Pipeline</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#installation" class="table-of-contents__link toc-highlight">Installation</a></li><li><a href="#preset-configuration" class="table-of-contents__link toc-highlight">Preset configuration</a></li><li><a href="#run-the-mining-pipeline" class="table-of-contents__link toc-highlight">Run the mining pipeline</a></li><li><a href="#audio-data-format-and-segmentation" class="table-of-contents__link toc-highlight">Audio data format and segmentation</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/pipelines/global_mining">Pipelines</a></li><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/stopes">stopes Modules</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/data-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Data Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/cookie-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Cookie Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.fb.com" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--light_HNdA footer__logo"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--dark_i4oU footer__logo"></a></div><div class="footer__copyright">Copyright © 2024 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/stopes/assets/js/runtime~main.6bbf2219.js"></script>
<script src="/stopes/assets/js/main.cb8faedb.js"></script>
</body>
</html>