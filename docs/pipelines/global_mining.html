<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-pipelines/global_mining">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Global Mining Pipeline | stopes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Global Mining Pipeline | stopes"><meta data-rh="true" name="description" content="You can launch the mining for a pair of languages with the following command:"><meta data-rh="true" property="og:description" content="You can launch the mining for a pair of languages with the following command:"><link data-rh="true" rel="icon" href="/stopes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining" hreflang="en"><link data-rh="true" rel="alternate" href="https://facebookresearch.github.io/stopes/docs/pipelines/global_mining" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZRD7WBVGH"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-9ZRD7WBVGH",{anonymize_ip:!0})</script><link rel="stylesheet" href="/stopes/assets/css/styles.4435c2e4.css">
<link rel="preload" href="/stopes/assets/js/runtime~main.673b6451.js" as="script">
<link rel="preload" href="/stopes/assets/js/main.221a2c9d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/stopes/"><div class="navbar__logo"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/stopes/img/logo.svg" alt="stopes Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">stopes</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/quickstart">Quickstart</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/stopes">Framework</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/pipelines/global_mining">State-of-the-art Pipelines</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><a href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">NLLB<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/stopes/docs/quickstart">Getting started with mining</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/stopes-modules">stopes Modules</a><button aria-label="Toggle the collapsible sidebar category &#x27;stopes Modules&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/stopes/docs/category/prebuilt-pipelines">Prebuilt Pipelines</a><button aria-label="Toggle the collapsible sidebar category &#x27;Prebuilt Pipelines&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/speech_mining">Speech Mining Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/stopes/docs/pipelines/global_mining">Global Mining Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/monolingual">NLLB Monolingual Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/stopes/docs/pipelines/distillation">NLLB Distillation Pipeline</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/stopes/docs/category/evaluation-toolkit">Evaluation Toolkit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Evaluation Toolkit&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/stopes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/stopes/docs/category/prebuilt-pipelines"><span itemprop="name">Prebuilt Pipelines</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Global Mining Pipeline</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Global Mining Pipeline</h1><h1>Basic Usage</h1><p>You can launch the mining for a pair of languages with the following command:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m stopes.pipelines.bitext.global_mining_pipeline </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">fuv </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">zul </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">demo_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">..</span><span class="token plain">./stopes-repo/demo +preset</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">demo </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">output_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">. </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">laser2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>(see the demo doc for a quick understanding of the <code>+preset</code> override)</p><p>This will run the required steps and try to re-use whatever step outputs has already been computed. So if you run this exact command multiple times (e.g. after a pre-emption in slurm), it will start from where it failed instead of recomputing everything.</p><p>Here is an example log:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">[global_mining][INFO] - output: ....../mining/global_mining/outputs/2021-11-02/08-56-40</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[global_mining][INFO] - working dir: ....../mining/global_mining/outputs/2021-11-02/08-56-40</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[mining_utils][WARNING] - No mapping for lang bn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[embed_text][INFO] - Number of shards: 55</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[embed_text][INFO] - Embed bn (hi), 55 files</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[stopes_launcher][INFO] - for encode.bn.55 found 55 already cached array results,0 left to compute out of 55</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[train_faiss_index][INFO] - lang=bn, sents=135573728, required=40000000, index type=OPQ64,IVF65536,PQ64</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[stopes_launcher][INFO] - index-train.bn.iteration_2 done from cache</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[stopes_launcher][INFO] - for populate_index.OPQ64,IVF65536,PQ64.bn found 44 already cached array results,11 left to compute out of 55</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[stopes_launcher][INFO] - submitted job array for populate_index.OPQ64,IVF65536,PQ64.bn: [&#x27;48535900_0&#x27;, ..., &#x27;48535900_10&#x27;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[mining_utils][WARNING] - No mapping for lang hi</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[embed_text][INFO] - Number of shards: 55</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[embed_text][INFO] - Embed hi (hi), 55 files</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[stopes_launcher][INFO] - for encode.hi.55 found 55 already cached array results,0 left to compute out of 55</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[train_faiss_index][INFO] - lang=hi, sents=162844151, required=40000000, index type=OPQ64,IVF65536,PQ64</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We can see that the launcher has found out that it doesn&#x27;t need to run the encode and train index steps for the bn lang (source language) and can skip straight to populating the index with embeddings, but it also already processed 44 shards for that step, so will only re-schedule jobs for 11 shards. In parallel, it is also processing the target language (hi) and found that it still needs to run the index training step as it also recovered all the encoded shards.</p><p>If you are using slurm as the launcher instead of the local setting, the pipeline also takes care of communicating with slurm, waiting for all slurm jobs to finish and synchronizing the consecutive jobs. See below on how to run single steps for debugging.</p><p>You can run the whole pipeline locally with:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg launcher.cluster</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">local</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h1>Understanding the Configuration</h1><p>The configuration is driven by <a href="https://hydra.cc/" target="_blank" rel="noopener noreferrer">Hydra</a>, this makes it sound way more complicated than it actually is. The first main difference is how the command line arguments are specified. Instead of using the <code>--arg=foobar</code> standard notation, Hydra introduces its <a href="https://hydra.cc/docs/1.0/advanced/override_grammar/basic/#basic-override-syntax" target="_blank" rel="noopener noreferrer">own notation</a> to be able to have a  more complete syntax. This is indeed odd, but once you are used to it, it provides a lot of benefits.</p><p>A second big change is that most of the things that can be changed in the pipeline are driven by yaml configuration files instead of having to change the script files. These configuration files are checked in and you can override them on the command line (see the examples above). The pipeline will log the actual full config+overrides in the output folder when you do a run, so that you can always look at the config that was used to generate a particular data folder.</p><p>The third major change, and main benefit, is that the configs are split in &quot;groups&quot; (hydra terminology) and you can override a whole group with another yaml file with a very simple syntax. For instance, the embed_text step has a set of pre-made configs in <code>global_mining/conf/embed_text</code> and you can swap between them. If you would like to make a new reusable/shared config for embed_text, you could put a new yaml file in that that folder (let say <code>global_mining/conf/embed_text/foobar.yaml</code>) and select it from the cli with:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">foobar</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>See the Data and Modules discussion below for more examples.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="outputs-and-working-dir">Outputs and Working Dir<a class="hash-link" href="#outputs-and-working-dir" title="Direct link to heading">​</a></h2><p>The output of the pipeline is set in the global_mining.yaml to be &quot;.&quot;, which means the current working directory. When running <code>global_mining_pipeline.py</code> it will by default create a new folder under <code>outputs/today_date/timeofrun</code> and make this your working directory. This means all your logs will be well organized. It also means that the main output of each step will go under that directory given the default configuration of <code>output_dir: .</code></p><p>Because you might run the pipeline multiple times for the same &quot;data run&quot; (e.g. if it fails with pre-emption in the middle, etc.), this default config means that you might end up with data spread across multiple date/time directories.</p><p>It&#x27;s therefore a good idea when you are doing a full run (not just testing), to specify a fixed outputs directory when launching the pipeline:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">output_dir</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">/myfinal/data/outputs</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This way logs and other temp files will go to the working directory, but the data will go to a clean central place.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="data">Data<a class="hash-link" href="#data" title="Direct link to heading">​</a></h2><p>The current data configuration for the pipeline takes a few parameters:</p><ul><li>data_version</li><li>iteration</li><li>data_shard_dir</li><li>shard_type</li><li>bname</li></ul><p>Because you will most often always use the same data for your runs, there is no need to specify this every time on the CLI or in the default config. There is a &quot;group&quot; under <code>global_mining/conf/data</code> where you can put common data sources. Checkout the demo config to see how to configure data. You can create a data config folder if you want to switch data without changing all other presets.</p><h1>Modules</h1><p>The pipeline is made of seven main steps:</p><ul><li>split_in_shards (optional)</li><li>embed_text</li><li>train_index</li><li>populate_index</li><li>merge_index</li><li>calculate_distances</li><li>mine_indexes</li><li>mine_sentences</li><li>merge_shards (optional)</li></ul><p>Each of them is configured as a &quot;group&quot; and their configurations can be overridden by switching groups on the cli as explained above. This override can also completely switch the code/module that is being used to compute this step, without changing the pipeline itself.</p><p><strong>Embedding Modules</strong></p><p>You can switch the actual encoder being used to choose between multiple encoders. For example, you can choose to use LaBSE, BERT, RoBERTa, or any other model from the sentence-transformers repo within the HuggingFace Model Hub (<a href="https://huggingface.co/sentence-transformers" target="_blank" rel="noopener noreferrer">https://huggingface.co/sentence-transformers</a>). Here’s an example of how to encode text using LaBSE (with encoder-specific options in blue):</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg  </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hf_roberta_large</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg  </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hf_labse</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>or you can choose any huggingface encoder by their name with:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py -c job </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg  </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">huggingface embed_text.encoder_model</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">sentence-transformers/LaBSE</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>These are shortcuts to common models, but you can switch to any other model in the HuggingFace Model Hub, see <code>hf_labse.yaml</code> for an example of how to change config.encoder.encoder_model. To utilise LASER you can use the following example command:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py -c job </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">laser2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embed_text.config.encoder.encoder_model</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">path_to_laser_model</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embed_text.config.encoder.spm_model</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">path_to_spm_model</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="splitting-and-merging-languages">Splitting and merging languages<a class="hash-link" href="#splitting-and-merging-languages" title="Direct link to heading">​</a></h3><p>For some large languages, the mining might fail because of out-of-memory errors, especially if the FAISS indexes are stored on GPU. To mitigate this probelm, you can split a language into shards, perform the mining on them in parallel, and then merge the results. </p><p>The first optional module, <code>split_in_shards</code>, can randomly split the language (inclusing both text files and metadata files, if they exist) into several shards.
To use this option, you should specify the parameter <code>max_shard_size</code>, and the languages with more total lines than this number will be automatically split into smaller shards. </p><p>Alternatively, you can manually split the data for the language and configure it as several separate &quot;languages&quot;, e.g. <code>eng0,eng1,eng2</code>. In this case, you can indicate in the mining config that they should be merged into a single language after mining:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">sharded_langs:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  eng:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    - eng0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    - eng1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    - eng2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>When you provide <code>max_shard_size</code> or <code>sharded_langs</code>, the module <code>merge_shards</code> is called in the end of the pipeline. It merges the mined bitexts for the sharded languages together and sorts the results (both text and meta files) in the order of decreasing alignment score.</p><p><strong>Note</strong> that the mined sentence pairs are filtered by the <a href="https://aclanthology.org/P19-1309/" target="_blank" rel="noopener noreferrer">margin score</a> that depends not only on the sentences themselves, but also on their nearest neighbours in the dataset. Therefore, when you mine parallel sentences from subsets of a language and then merge them, you may end up with more sentence pairs than if you mined from the whole language at once. This effect may be countered by adjusting the mining threshold or by filtering the sentence pairs after the mining.</p><h1>Sweeping (multi-run)</h1><p>One of the benefits of the hydra cli override syntax, is that you can ask hydra to try different variations of the configuration with a simple command line. Hydra calls this <a href="https://hydra.cc/docs/1.0/tutorials/basic/running_your_app/multi-run/" target="_blank" rel="noopener noreferrer">&quot;multi-run&quot;</a> and it lets you specify variations to your config that you would like to try.</p><p>For instance, if you would like to run the pipeline on multiple languages, you can do:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py -m </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">en </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn,hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The <code>-m</code> parameter tells the pipeline to start with multi-run and <code>tgt_lang=bn,hi</code> tells it to make two runs, one for en-bn and one for en-hi.</p><p> You could also sweep over the lang and the encoders with:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python global_mining_pipeline.py -m </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">src_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">en </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">tgt_lang</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">bn,hi +data</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ccg </span><span class="token assign-left variable" style="color:rgb(191, 199, 213)">embed_text</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">hf_roberta_large,hf_labse</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h1>NMT model training on mined bitexts</h1><p>Once a mined bitext has been produced, <code>stopes</code> can then run an end-to-end bilingual NMT system. It follows the following steps:</p><ol><li>Takes as input a mined bitext (format: alignment-score <!-- -->[tab]<!-- --> text <!-- -->[tab]<!-- --> text)</li><li>Applies threshold filters based on alignment score and max number of alignments to use for training</li><li>Applies moses preprocessing (on bitext only)</li><li>Trains spm (on bitext only)</li><li>Spm-encodes bitext and chosen evaluation data</li><li>Binarizes files for fairseq</li><li>Trains bilingual NMT using <code>fairseq-train</code> on binarized data</li><li>Runs <code>fairseq-generate</code> on binarized evaluation data for all model checkpoints</li><li>Calculates BLEU scores</li></ol><h1>Run it</h1><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m stopes.pipelines.bitext.nmt_bitext_eval                   \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">src_lang=lin_Latn tgt_lang=eng_Latn                                 \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_file_mined_data_tsv=/path/to/your/bitext.tsv                  \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">preproc_binarize_mined.test_data_dir.dataset_name=flores200         \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">preproc_binarize_mined.test_data_dir.base_dir=/path/to/flores200    \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output_dir=/directory/to/store/preprocessed/data/and/checkpoints    \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">launcher.cache.caching_dir=/path/to/cache                           \</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">maximum_epoch=20</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>NOTE</strong>: In order for the training pipeline to know which column of the bitext corresponds to the selected <code>src_lang</code> and <code>tgt_lang</code>, it presumes that the two text columns in the bitext are ordered by their sorted language names. For example, for a <code>eng-lin</code> bitext, the format is: alignment-score <!-- -->[tab]<!-- --> english-text <!-- -->[tab]<!-- --> lingala-text (not alignment-score <!-- -->[tab]<!-- --> lingala-text <!-- -->[tab]<!-- --> english-text). </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="outputs">Outputs<a class="hash-link" href="#outputs" title="Direct link to heading">​</a></h2><p>The NMT pipeline will create the following directories in the specified <code>output_dir</code>:</p><ul><li><code>bin_dir</code>: moses preprocessed, spm-encoded, and binarized data.</li><li><code>trained_models</code>: checkpoints from <code>fairseq-train</code>. <strong>Note</strong>: this directory will also contain files containing the outputs of both <code>fairseq-generate</code> (files ending in <code>.out</code>) and the corresponding BLEU evaluations for each checkpoint (files ending in <code>.bleu</code>).</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-data">Evaluation data<a class="hash-link" href="#evaluation-data" title="Direct link to heading">​</a></h2><p>To find the evaluation data for your chosen languages, <code>stopes</code> needs to know the relevant path. See <code>path</code> in <code>stopes/pipelines/bitext/conf/preproc_binarize_mined/standard_conf.yaml</code>. Currently it defaults to the format of the <code>flores200</code> dataset. To use this, please <a href="https://github.com/facebookresearch/flores/tree/main/flores200" target="_blank" rel="noopener noreferrer">download flores200</a>. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="example-overrides">Example overrides<a class="hash-link" href="#example-overrides" title="Direct link to heading">​</a></h2><p><strong>Spm training</strong></p><p><code>spm.train.config.vocab_size=7000</code></p><p><strong>Model configuation</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.params.optimization.lr=[0.0001]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.params.optimization.update_freq=[8]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.params.model.encoder_layers=6</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.params.model.encoder_embed_dim=512</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.params.model.dropout=0.3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_fairseq.config.num_gpus=8</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/pipelines/global_mining.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/stopes/docs/pipelines/speech_mining"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Speech Mining Pipeline</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/stopes/docs/pipelines/monolingual"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">NLLB Monolingual Pipeline</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#outputs-and-working-dir" class="table-of-contents__link toc-highlight">Outputs and Working Dir</a></li><li><a href="#data" class="table-of-contents__link toc-highlight">Data</a><ul><li><a href="#splitting-and-merging-languages" class="table-of-contents__link toc-highlight">Splitting and merging languages</a></li></ul></li><li><a href="#outputs" class="table-of-contents__link toc-highlight">Outputs</a></li><li><a href="#evaluation-data" class="table-of-contents__link toc-highlight">Evaluation data</a></li><li><a href="#example-overrides" class="table-of-contents__link toc-highlight">Example overrides</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/pipelines/global_mining">Pipelines</a></li><li class="footer__item"><a class="footer__link-item" href="/stopes/docs/stopes">stopes Modules</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebookresearch/stopes" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/data-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Data Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/cookie-policy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Cookie Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.fb.com" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--light_HNdA footer__logo"><img src="/stopes/img/meta_opensource_logo_negative.svg" alt="Meta Open Source Logo" class="themedImage_ToTc themedImage--dark_i4oU footer__logo"></a></div><div class="footer__copyright">Copyright © 2023 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/stopes/assets/js/runtime~main.673b6451.js"></script>
<script src="/stopes/assets/js/main.221a2c9d.js"></script>
</body>
</html>