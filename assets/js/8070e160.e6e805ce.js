"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[651],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=i,h=c["".concat(l,".").concat(m)]||c[m]||u[m]||r;return n?a.createElement(h,o(o({ref:t},d),{},{components:n})):a.createElement(h,o({ref:t},d))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var p=2;p<r;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},2257:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const r={sidebar_position:1},o="Getting started with stopes",s={unversionedId:"quickstart",id:"quickstart",title:"Getting started with stopes",description:"Welcome to stopes, this is a quickstart guide to discover how to run automated pipelines with stopes. In this example, you'll be running",source:"@site/docs/quickstart.md",sourceDirName:".",slug:"/quickstart",permalink:"/stopes/docs/quickstart",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/quickstart.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"quickstartSidebar",next:{title:"stopes Modules",permalink:"/stopes/docs/category/stopes-modules"}},l={},p=[{value:"Installation",id:"installation",level:2},{value:"Getting Data",id:"getting-data",level:2},{value:"Configuring the pipeline",id:"configuring-the-pipeline",level:2},{value:"Run the Pipeline",id:"run-the-pipeline",level:2},{value:"Try using a different encoder",id:"try-using-a-different-encoder",level:2}],d={toc:p};function u(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"getting-started-with-stopes"},"Getting started with stopes"),(0,i.kt)("p",null,"Welcome to ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes"),", this is a quickstart guide to discover how to run automated pipelines with ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes"),". In this example, you'll be running\nglobal mining with the ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes")," toolchain. (Inspired by\n",(0,i.kt)("a",{parentName:"p",href:"https://ai.facebook.com/blog/ccmatrix-a-billion-scale-bitext-data-set-for-training-translation-models/"},"CCMatrix"),")."),(0,i.kt)("h2",{id:"installation"},"Installation"),(0,i.kt)("p",null,"Follow the installation steps from the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/stopes/blob/main/README.md"},"project's README"),", we recommend doing this in a separate ",(0,i.kt)("a",{parentName:"p",href:"https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html"},"conda environment"),"."),(0,i.kt)("h2",{id:"getting-data"},"Getting Data"),(0,i.kt)("p",null,"To run the global mining pipeline, you first need to get some monolingual data.\nThe ",(0,i.kt)("a",{parentName:"p",href:"https://statmt.org/wmt22/large-scale-multilingual-translation-task.html"},"WMT22 Shared Task: Large-Scale Machine Translation Evaluation for African\nLanguages"),"\nhas some interesting monolingual data for some African languages."),(0,i.kt)("p",null,"You also need some trained encoder, we usually use ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes")," with LASER and we can\nfind such trained encoders for the languages in the WMT22 shared task too."),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"demo/prepare.sh")," script will download the monolingual data and LASER encoders\nfor you. Start by running this script and wait for the download to finish."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("inlineCode",{parentName:"p"},"prepare.sh")," was built for the quickstart demo, it will only download the encoders and data released as part of the African Languages workshop. The NLLB project has released ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/LASER/tree/main/nllb/"},"many encoders")," and data that you can leverage with ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes"),".")),(0,i.kt)("h2",{id:"configuring-the-pipeline"},"Configuring the pipeline"),(0,i.kt)("p",null,"In ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes")," pipelines, we use ",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc/"},"hydra"),' to configure the runs.\nWith hydra, you can configure everything with "overrides" on the cli, but it\'s\noften easier to put the configurations in yaml files as there is a lot of things\nto setup.'),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"stopes/pipelines/bitext/conf/preset/demo.yaml")," is a demo configuration for the\ndata and encoders that we've downloaded in the previous steps. Check out the\ncomments in that file."),(0,i.kt)("p",null,"The important parts of that preset config is:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"we setup the launcher to run on your local computer (no need for a cluster)"),(0,i.kt)("li",{parentName:"ol"},"we setup an alias for a ",(0,i.kt)("inlineCode",{parentName:"li"},"demo_dir")," folder, so you can point to the\ndata/models from the cli"),(0,i.kt)("li",{parentName:"ol"},"we setup some information about the ",(0,i.kt)("inlineCode",{parentName:"li"},"data"),":",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"some naming, to get nice file names as outputs"),(0,i.kt)("li",{parentName:"ul"},"where the data is found (with ",(0,i.kt)("inlineCode",{parentName:"li"},"shard_glob"),")"))),(0,i.kt)("li",{parentName:"ol"},"we tell the pipeline where to find the encoder and SentencePiece model (SPM) uses\nto embed the text. We do that for each lang in ",(0,i.kt)("inlineCode",{parentName:"li"},"lang_configs"),". Practically,\nif you are only processing a few languages, you don't need so many entries,\nhere we preset them for all languages from the WMT22 task")),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Language codes are important, but not standardized everywhere. The ",(0,i.kt)("inlineCode",{parentName:"p"},"stopes")," library does not make any assumptions to what codes you are using. As you will see in the configuration and the prepare script, codes are mostly important in naming data input files. If you want to use a different coding scheme, make sure that the files and config use the same naming conventions.")),(0,i.kt)("h2",{id:"run-the-pipeline"},"Run the Pipeline"),(0,i.kt)("p",null,"You can now start the pipeline with:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python -m stopes.pipelines.bitext.global_mining_pipeline src_lang=fuv tgt_lang=zul demo_dir=.../stopes-repo/demo +preset=demo output_dir=. embed_text=laser3\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"src_lang")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"tgt_lang")," specify the pair of languages we want to process,"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"demo_dir")," is the new variable we introduce in our preset/demo.yaml file, to\npoint to where the ",(0,i.kt)("inlineCode",{parentName:"li"},"prepare.sh")," script downloaded our data; make sure to\nspecify an absolute path,"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"+preset=demo")," tells hydra to load the demo.yaml preset file to set our\ndefaults (the ",(0,i.kt)("inlineCode",{parentName:"li"},"+")," here is because we are telling hydra to append a group that\ndoesn't exist in the default config, see the ",(0,i.kt)("a",{parentName:"li",href:"https://hydra.cc/docs/1.0/advanced/override_grammar/basic/#basic-override-syntax"},"hydra\ndoc"),"\nfor details),"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"output_dir")," specifies where we want the output (current run directory),"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"embed_text=laser3")," tells the pipeline to use the laser3 encoding code to load\nthe models and encode the text.")),(0,i.kt)("h2",{id:"try-using-a-different-encoder"},"Try using a different encoder"),(0,i.kt)("p",null,"In the previous run, we used ",(0,i.kt)("inlineCode",{parentName:"p"},"embed_text=laser3"),", which will encode text with\nthe language specific laser3, but you can also use other encoders. For instance,\nstopes ships with ",(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/sentence-transformers"},"HuggingFace\nsentence-transformers"),", so you can\nuse different encoders if you want to experiment."),(0,i.kt)("p",null,"You need to install ",(0,i.kt)("inlineCode",{parentName:"p"},"sentence-transformers")," in your environment:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install --user sentence-transformers\n")),(0,i.kt)("p",null,"Here is an example to run LaBSE:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python -m stopes.pipelines.bitext.global_mining_pipeline src_lang=fuv tgt_lang=zul demo_dir=.../stopes-repo/demo +preset=demo output_dir=. embed_text=hf_labse lang_configs=null\n")),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("h2",{parentName:"admonition",id:"explore-more"},"Explore More"),(0,i.kt)("p",{parentName:"admonition"},"Check out these docs to learn more:"),(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"category/prebuilt-pipelines"},"Prebuilt Pipelines")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"stopes"},(0,i.kt)("inlineCode",{parentName:"a"},"stopes")," Module Framework")))))}u.isMDXComponent=!0}}]);