"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[510],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>u});var i=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,r=function(e,t){if(null==e)return{};var n,i,r={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=i.createContext({}),p=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=p(e.components);return i.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),m=p(n),u=r,g=m["".concat(l,".").concat(u)]||m[u]||c[u]||a;return n?i.createElement(g,o(o({ref:t},d),{},{components:n})):i.createElement(g,o({ref:t},d))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,o=new Array(a);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<a;p++)o[p]=n[p];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},9761:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var i=n(7462),r=(n(7294),n(3905));const a={sidebar_position:1},o="Expressive parallel alignments",s={unversionedId:"pipelines/expressive_alignments",id:"pipelines/expressive_alignments",title:"Expressive parallel alignments",description:'We extend the parallel speech alignment method described in Seamless Communication et al. (2023) to align pairs not only in terms of meaning, but also in terms of expressivity. Specifically, the pipeline is extended to allow for additional processing of the k-nearest-neighbors and introduces an option to add auxiliary_embeddings, which are expected to be a complementary source of prosodic input to the traditional semantic-based inputs e.g. SONAR speech embeddings. The prosodic scores/similarity from the auxiliary embeddings are then "blended" together with the traditional margin-based scores using the formula:',source:"@site/docs/pipelines/expressive_alignments.md",sourceDirName:"pipelines",slug:"/pipelines/expressive_alignments",permalink:"/stopes/docs/pipelines/expressive_alignments",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/pipelines/expressive_alignments.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"quickstartSidebar",previous:{title:"Prebuilt Pipelines",permalink:"/stopes/docs/category/prebuilt-pipelines"},next:{title:"Speech Mining Pipeline",permalink:"/stopes/docs/pipelines/speech_mining"}},l={},p=[],d={toc:p};function c(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,i.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"expressive-parallel-alignments"},"Expressive parallel alignments"),(0,r.kt)("p",null,"We extend the parallel speech alignment method described in Seamless Communication et al. (2023) to align pairs not only in terms of meaning, but also in terms of expressivity. Specifically, the pipeline is extended to allow for additional processing of the k-nearest-neighbors and introduces an option to add ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary_embeddings"),", which are expected to be a complementary source of prosodic input to the traditional semantic-based inputs e.g. ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/SONAR"},"SONAR speech embeddings"),'. The prosodic scores/similarity from the auxiliary embeddings are then "blended" together with the traditional margin-based scores using the formula:'),(0,r.kt)("p",null,"$$ \\text{blended-score}(x, y) = \\alpha \\cdot \\text{margin} + (1 - \\alpha) \\cdot \\text{auxiliary-score} $$"),(0,r.kt)("p",null,"where $\\alpha$ controls how much to weight the ",(0,r.kt)("inlineCode",{parentName:"p"},"margin")," scores against the ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary-score")," (i.e. the prosodic similarity score). By default, the ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary-score")," will be calculated as the cosine between the source and candidate neighbors using the auxiliary embeddings. However, there is also an option to perform PCP inference using AutoPCP (Seamless Communication et al., 2023). In this instance, the ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary-score")," will be the AutoPCP outputs. "),(0,r.kt)("hr",null),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"NOTE")),(0,r.kt)("p",null,"if no auxiliary-embeddings are provided, then the logic will not branch from the existing speech alignment pipeline."),(0,r.kt)("hr",null),(0,r.kt)("p",null,"Below is an example configuration of how to provide the ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary_embeddings")," for two language configurations: English (en) and Spanish (es). For ",(0,r.kt)("inlineCode",{parentName:"p"},"auxiliary_embeddings")," which are already pre-computed, you can simply pass the option: ",(0,r.kt)("inlineCode",{parentName:"p"},"existing_aux_embedding_glob")," using a similar structure to that shown below. For other options, please see the README for the existing alignment pipeline."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"data_dir: /path/to/data\nlang_configs:\n  es:\n    existing_embedding_glob: ${data_dir}/sonar-speech-embeddings/es_emb.[0-9][0-9][0-9].npy\n    existing_aux_embedding_glob: ${data_dir}/aux_embeddings/es_emb.[0-9][0-9][0-9].npy\n  en:\n    existing_embedding_glob: ${data_dir}/sonar-speech-embeddings/en_emb.[0-9][0-9][0-9].npy\n    existing_aux_embedding_glob: ${data_dir}/aux_embeddings/en_emb.[0-9][0-9][0-9].npy\n")))}c.isMDXComponent=!0}}]);