[build-system]
requires = ["flit_core >=3.2,<4", "setuptools"]
build-backend = "flit_core.buildapi"

[project]
name = "stopes"
readme = "README.md"
authors = [{name = "Facebook AI Research"}]
requires-python = ">=3.8"
dynamic = ["version", "description"]

dependencies = [
  "hydra-core>=1.2.0",
  "joblib",
  "submitit>=1.4.5",
  "tqdm",
  "posix_ipc",
  "pyarrow>=13.0.0"
]
# zip_safe = false
classifiers=[
    "License :: OSI Approved :: MIT License",
    "Topic :: Scientific/Engineering",
    "Development Status :: 4 - Beta",
]

[project.urls]
  Source = "https://github.com/facebookresearch/stopes"
  Tracker = "https://github.com/facebookresearch/stopes/issues"

[project.optional-dependencies]
  mono = [
    "xxhash",
    "fasttext",
    "sentence_splitter",
    # "kenlm",
    "sacremoses",
    "sentencepiece",
    "indic-nlp-library",
    "emoji",
    "pythainlp",
    "botok",
    "khmer-nltk",
    "laonlp",
  ]
  mining = [
    "requests",
    "fairscale",
   # "fairseq==0.12.1",
    "faiss-cpu",
    "sentencepiece",
    "numpy>=1.21",
  ]
  mining_gpu = [
    "faiss-gpu",
  ]
  speech = [
    "hanziconv",
    "inflect",
    "tnkeeh",
    "torchaudio",
    "num2words",
    "pandas",
    "unidecode",
    "transformers",
    "whisper",
    "encodec",
    "demucs",
    "librosa"
  ]
  video_alignment = [
    "librosa",
    "sentence_transformers",
    "torchaudio",
    "scipy",
    "pandas",
    "pyarrow>=13.0.0",
    "numba",
    "transformers",
    "openai-whisper==20230314",
    "fairseq2==0.2.*",
    "sonar-space==0.2.*",
  ]
  vocal_style_sim = [
    "s3prl",
  ]
  sonar_mining = [
    "sonar-space==0.2.*",
    "fairseq2==0.2.*",
  ]
  dev = [
      # Test
      "pytest>=4.3.0",
      "pytest-asyncio>=0.15.0",
      "pytest-cov>=2.6.1",
      "coverage[toml]>=5.1",
      # Format
      "black==22.3.0",
      "isort>=5.12.0",
      # Linters
      "mypy>=1.1.1",
      "types-emoji",
      "types-requests",
      "types-PyYAML",
      "pylint>=2.8.0",
      # Release
      "flit>=3.5.1"
  ]
  hmine = [
    "bs4",
    "func_argparse",
    "nltk",
    "pandas",
    "scipy",
    "scikit-learn",
    "xxhash",
  ]
  blaser = [
    "scipy",
    "numpy",
    "torch",
  ]
  alti = [
    "einops",
    "numpy",
    "omegaconf",
    "torch",
    # fairseq is also a dependency, but it must be installed separately
  ]
  auto_pcp = [
    "transformers",
    "pandas",
    "scipy",
  ]
  local_prosody = [
    "transformers",
    "pandas",
    "syllables",
    "phonemizer",
    "ipapy",
    "nltk",
    "sacremoses",
  ]

[tool.black]
# Black defaults are great !

[tool.isort]
profile = "black"
skip_gitignore = true
skip_glob = ["website/*", "*.pyx", 'ust/*']

[tool.mypy]
python_version = "3.8"
show_error_codes = true
check_untyped_defs = true
ignore_missing_imports = true
implicit_optional = true
implicit_reexport = true

files = [
  "stopes/"
]
# Generated with: mypy | cut -d':' -f1 | uniq -c | sort -nr
# It's only allowed to remove files, not to add more (ಠ_ಠ)
exclude = [
  "stopes/modules/bitext/mining/mine_bitext_indexes_utils.py", # 49
  "stopes/pipelines/distillation/distillation_pipeline.py", # 22
  "stopes/eval/blaser/model.py", # 22
  "stopes/pipelines/filtering/filter.py", # 12
  "stopes/modules/preprocess/split_in_shards.py", # 12
  "stopes/modules/bitext/mining/merge_shards.py", # 12
  "stopes/eval/blaser/train.py", # 12
  "stopes/modules/speech/shas/shas.py", # 11
  "stopes/utils/tts_preprocessing/cmn.py", # 10
  "stopes/pipelines/bitext/shard_and_shuffle.py", # 10
  "stopes/pipelines/prepare_data/prepare_data.py", # 9
  "stopes/pipelines/monolingual/dedup_files.py", # 9
  "stopes/modules/bitext/mining/mine_bitext_sentences_utils.py", # 9
  "stopes/eval/blaser/score.py", # 9
  "stopes/eval/alti/alignment/align.py", # 9
  "stopes/modules/tests/test_mine_index_utils.py", # 8
  "stopes/modules/preprocess/laser_sentence_encoder.py", # 8
  "stopes/utils/embedding_utils.py", # 7
  "stopes/pipelines/monolingual/monolingual_pipeline.py", # 7
  "stopes/modules/tests/test_populate_index_port.py", # 7
  "stopes/modules/speech/whisper.py", # 7
  "stopes/core/jobs_registry/registry.py", # 7
  "stopes/pipelines/prepare_data/dedup_sharding.py", # 6
  "stopes/pipelines/filtering/scripts/populate_data_conf.py", # 6
  "stopes/pipelines/distillation/distillation_bitext_processor.py", # 6
  "stopes/pipelines/bitext/ExtractMetaLineProc.py", # 6
  "stopes/modules/tests/test_split_merge_langs.py", # 6
  "stopes/core/jobs_registry/submitit_slurm_job.py", # 6
  "stopes/pipelines/prepare_data/validate.py", # 5
  "stopes/pipelines/monolingual/monolingual_line_processor.py", # 5
  "stopes/pipelines/filtering/filters/lid.py", # 5
  "stopes/modules/preprocess/multiproc_bitext_processor.py", # 5
  "stopes/modules/evaluation/generate_multi_bleu_detok_module.py", # 5
  "stopes/modules/bitext/indexing/populate_faiss_index.py", # 5
  "stopes/utils/tts_preprocessing/numbers/__init__.py", # 4
  "stopes/modules/translation/fairseq_generate.py", # 4
  "stopes/modules/speech/shas/data.py", # 4
  "stopes/eval/alti/wrappers/transformer_wrapper.py", # 4
  "stopes/eval/alti/wrappers/multilingual_transformer_wrapper.py", # 4
  "stopes/eval/alti/alti_metrics/nllb_alti_detector.py", # 4
  "stopes/core/jobs_registry/stopes_job.py", # 4
  "stopes/pipelines/translate/translation_pipeline.py", # 3
  "stopes/pipelines/prepare_data/build_vocab.py", # 3
  "stopes/pipelines/eval/eval_blaser.py", # 3
  "stopes/pipelines/bitext/dedup_local_and_global.py", # 3
  "stopes/pipelines/bitext/bitext_eval.py", # 3
  "stopes/modules/tests/test_embedding_utils.py", # 3
  "stopes/modules/preprocess/mining_speech_encoder.py", # 3
  "stopes/modules/bitext/mining/calculate_distances.py", # 3
  "stopes/utils/tts_preprocessing/cleaners.py", # 2
  "stopes/pipelines/monolingual/utils/predict_lid.py", # 2
  "stopes/pipelines/bitext/nmt_bitext_eval.py", # 2
  "stopes/modules/tests/test_text_input.py", # 2
  "stopes/modules/preprocess/multiproc_line_processor.py", # 2
  "stopes/modules/bitext/indexing/sample_embedding_module.py", # 2
  "stopes/eval/blaser/model.py",
  "stopes/eval/blaser/train.py",
  "stopes/eval/blaser/score.py",
  "stopes/ust_common/evaluation.py", # 92
  "stopes/ust_common/text/numbers.py", # 25
  "stopes/ust_common/tabulation.py", # 15
  "stopes/ust_common/text/cn_tn.py", # 10
  "stopes/ust_common/agg_results.py", # 9
  "stopes/ust_common/sweep_utils.py", # 8
  "stopes/ust_common/lib/audio.py", # 8
  "stopes/ust_common/lib/manifests.py", # 7
  "stopes/ust_common/lib/lpc.py", # 6
  "stopes/ust_common/generation/asr_utils.py", # 6
  "stopes/ust_common/viewer/notebook.py", # 5
  "stopes/ust_common/lib/webrtc_vad.py", # 5
  "stopes/ust_common/lib/__init__.py", # 5
  "stopes/ust_common/generation/tts_utils.py", # 4
  "stopes/ust_common/sweep/slurm.py", # 2
  "stopes/ust_common/sweep/fblearner.py", # 1
  "stopes/ust_common/lib/f0.py", # 1
  "stopes/ust_common/generation/vocoder_utils/vocoder.py", # 1
  "stopes/ust_common/utils/model_export.py", # 1
]

[tool.pytest.ini_options]
minversion = "6.0"
testpaths = ["stopes"]
python_files = [
  "test_*.py",
  "monolingual/utils/*.py"
]
asyncio_mode = "auto"
norecursedirs = [
  "ust/*",
  "stopes/utils/aligner_utils", # it imports from a non-main branch of fairseq
  "stopes/eval/local_prosody/unity2_forced_aligner_f1", # it imports the package above
]
